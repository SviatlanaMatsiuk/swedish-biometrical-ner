{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Named Entity Recognition (NER) and Entity Linking"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:  \n",
    "Sviatlana Matsiuk  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Load data"
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2025-03-01T14:10:40.275373Z",
     "start_time": "2025-03-01T14:10:40.140536Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "data_folder = \"data/\"\n",
    "files = [\"1177_annotated_sentences.txt\", \"LT_annotated_60.txt\", \"Wiki_annotated_60.txt\"]\n",
    "\n",
    "dataset = []\n",
    "for file in files:\n",
    "    with open(os.path.join(data_folder, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        dataset.extend(lines)"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2. Dataset Selection and Preprocessing\n",
    "The dataset includes three files:\n",
    "- 1177_annotated_sentences.txt** (from \"1177 Vårdguiden\")\n",
    "- LT_annotated_60.txt (from Läkartidningen)\n",
    "- Wiki_annotated_60.txt (from Swedish Wikipedia)\n",
    "\n",
    "### **Preprocessing Steps**\n",
    "1. **Load and tokenize** text using **Kb-BERT tokenizer**.\n",
    "2. **Align labels** with tokenized words based on **BIO tagging**:\n",
    "   - **(Disorders/Diseases)** → `B-DIS`, `I-DIS`\n",
    "   - **[Pharmaceutical Drugs]** → `B-DRUG`, `I-DRUG`\n",
    "   - **{Anatomical Structures}** → `B-ANAT`, `I-ANAT`"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T22:00:08.872459Z",
     "start_time": "2025-02-21T22:00:00.057677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load Swedish Kb-BERT tokenizer\n",
    "model_name = \"KB/bert-base-swedish-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T22:00:11.728734Z",
     "start_time": "2025-02-21T22:00:08.873471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "label2id = {\n",
    "    \"O\": 0,         # Outside any entity\n",
    "    \"B-DIS\": 1,     # Beginning of Disorder/Finding `()`\n",
    "    \"I-DIS\": 2,     # Inside Disorder/Finding\n",
    "    \"B-DRUG\": 3,    # Beginning of Pharmaceutical Drug `[]`\n",
    "    \"I-DRUG\": 4,    # Inside Pharmaceutical Drug\n",
    "    \"B-ANAT\": 5,    # Beginning of Body Structure `{}`\n",
    "    \"I-ANAT\": 6     # Inside Body Structure\n",
    "}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "import re\n",
    "\n",
    "def load_ner_data(file_path):\n",
    "    sentences, labels = [], []\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            words = []\n",
    "            label_seq = []\n",
    "            i = 0\n",
    "\n",
    "            while i < len(line):\n",
    "                if line[i] in \"([{\" and i + 1 < len(line):\n",
    "                    entity_type = (\n",
    "                        \"B-DIS\" if line[i] == \"(\" else\n",
    "                        \"B-DRUG\" if line[i] == \"[\" else\n",
    "                        \"B-ANAT\" if line[i] == \"{\" else \"O\"\n",
    "                    )\n",
    "                    i += 1\n",
    "                    entity_words = []\n",
    "                    \n",
    "                    while i < len(line) and line[i] not in \")]}\":\n",
    "                        entity_words.append(line[i])\n",
    "                        i += 1\n",
    "\n",
    "                    entity_text = \"\".join(entity_words).strip()\n",
    "                    entity_tokens = entity_text.split()\n",
    "\n",
    "                    if entity_tokens:\n",
    "                        words.append(entity_tokens[0])\n",
    "                        label_seq.append(label2id[entity_type])\n",
    "                        \n",
    "                        for subword in entity_tokens[1:]:\n",
    "                            words.append(subword)\n",
    "                            i_tag = entity_type.replace(\"B-\", \"I-\")\n",
    "                            label_seq.append(label2id[i_tag])\n",
    "                \n",
    "                else:\n",
    "                    word_match = re.match(r\"\\S+\", line[i:])\n",
    "                    if word_match:\n",
    "                        word = word_match.group(0)\n",
    "                        words.append(word)\n",
    "                        label_seq.append(label2id[\"O\"])  # \"O\" label\n",
    "                        i += len(word) - 1\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            if words:\n",
    "                sentences.append(words)\n",
    "                labels.append(label_seq)\n",
    "\n",
    "    return sentences, labels"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T22:00:19.746839Z",
     "start_time": "2025-02-21T22:00:11.729432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load files\n",
    "all_sentences, all_labels = [], []\n",
    "for file in files:\n",
    "    sentences, labels = load_ner_data(os.path.join(data_folder, file))\n",
    "    all_sentences.extend(sentences)\n",
    "    all_labels.extend(labels)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T22:00:24.220500Z",
     "start_time": "2025-02-21T22:00:24.217910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sanity check\n",
    "for idx in range(5):\n",
    "    print(f\"Sentence {idx}: {all_sentences[idx]}\")\n",
    "    print(f\"Labels {idx}: {all_labels[idx]}\")\n",
    "    print(\"-\" * 50)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0: ['Memantin', 'Ebixa', 'ger', 'sällan', 'några', 'biverkningar.']\n",
      "Labels 0: [0, 1, 0, 0, 0, 0]\n",
      "--------------------------------------------------\n",
      "Sentence 1: ['Det', 'är', 'också', 'lättare', 'att', 'dosera', 'flytande', 'medicin', 'än', 'att', 'dela', 'på', 'tabletter.']\n",
      "Labels 1: [0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------\n",
      "Sentence 2: ['Förstoppning', 'är', 'ett', 'vanligt', 'problem', 'hos', 'äldre.']\n",
      "Labels 2: [1, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------\n",
      "Sentence 3: ['Medicinen', 'kan', 'också', 'göra', 'att', 'man', 'blöder', 'lättare', 'eftersom', 'den', 'påverkar', 'blodets', 'förmåga', 'att', 'levra', 'sig.']\n",
      "Labels 3: [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
      "--------------------------------------------------\n",
      "Sentence 4: ['Barn', 'har', 'större', 'möjligheter', 'att', 'samarbeta', 'om', 'de', 'i', 'förväg', 'får', 'veta', 'vad', 'som', 'ska', 'hända.']\n",
      "Labels 4: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2025-02-21T22:00:26.552494Z",
     "start_time": "2025-02-21T22:00:25.415772Z"
    }
   },
   "source": [
    "# Convert to Hugging Face dataset\n",
    "ner_dataset = Dataset.from_dict({\n",
    "    \"tokens\": all_sentences,\n",
    "    \"labels\": all_labels\n",
    "})"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The dataset was then converted into **Hugging Face’s Dataset format**, making it ready for fine-tuning.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3. Model Selection: Why Kb-BERT?**\n",
    "We compared available LLMs for **Swedish NER** and considered two approaches:\n",
    "1. **Fine-tune a Swedish LLM** (preferred)\n",
    "2. **Translate data to English and use BioBERT** (not chosen due to translation errors)\n",
    "\n",
    "| Model | Language | Pretraining Domain | Pros | Cons |\n",
    "|--------|----------|--------------------|------|------|\n",
    "| **Kb-BERT** *(KB/bert-base-swedish-cased)* | Swedish | Wikipedia, news, legal texts | - Trained on **Swedish**<br>- Preserves **Swedish syntax** | - No **biomedical training** |\n",
    "| **BioBERT** *(biobert-base-cased)* | English | Biomedical texts | - Trained on **medical** data | - Requires **translation** (risk of errors) |\n",
    "| **mBERT** *(bert-base-multilingual-cased)* | 100+ languages | General multilingual text | - Supports **Swedish** | - Weaker **NER performance** than monolingual models |\n",
    "\n",
    "### **Why Kb-BERT?**\n",
    " **Trained on Swedish** → No translation required  \n",
    " **Monolingual model** → Outperforms mBERT for Swedish  \n",
    " **Good for fine-tuning** → Can be adapted for medical text  \n",
    "\n",
    "Using **BioBERT** would introduce translation **errors** and **lose domain-specific Swedish terminology**. Therefore, **Kb-BERT was chosen as the best model for fine-tuning**.\n",
    "\n",
    "---\n",
    "\n",
    "Next, we will proceed with **fine-tuning Kb-BERT on the dataset** to improve its biomedical NER capabilities.\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 4: Fine-Tuning Kb-BERT for Swedish Biomedical NER"
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2025-02-21T22:00:27.037195Z",
     "start_time": "2025-02-21T22:00:26.861592Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KB/bert-base-swedish-cased\")\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],          \n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    all_labels = []\n",
    "    for batch_index, label_seq in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=batch_index)\n",
    "        \n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_seq[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label_seq[previous_word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        all_labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = all_labels\n",
    "    return tokenized_inputs"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T22:01:25.597424Z",
     "start_time": "2025-02-21T22:00:27.642770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply processing\n",
    "tokenized_dataset = ner_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    batch_size=16\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/795399 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27a0247884634fe384fdfea9509618a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To ensure that our model correctly recognizes named entities, we:\n",
    "1. **Tokenized sentences** using the Kb-BERT tokenizer.\n",
    "2. **Aligned entity labels** to tokenized words.\n",
    "3. **Handled subword tokenization** using the BIO-tagging scheme.\n",
    "4. **Converted the dataset into a format compatible with Hugging Face Transformers**.\n",
    "\n",
    "Now we are ready for data training\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 5: Model Training and Evaluation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **5.1 Training Configuration**\n",
    "- **Model:** `KB/bert-base-swedish-cased`\n",
    "- **Batch Size:** 8\n",
    "- **Learning Rate:** `5e-5`\n",
    "- **Epochs:** 3\n",
    "- **Optimizer:** AdamW\n",
    "- **Evaluation Strategy:** Per epoch"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T22:01:29.151664Z",
     "start_time": "2025-02-21T22:01:29.047913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "val_dataset   = split_dataset[\"test\"]"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T22:01:33.546961Z",
     "start_time": "2025-02-21T22:01:29.987696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"KB/bert-base-swedish-cased\",\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at KB/bert-base-swedish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T22:01:34.820162Z",
     "start_time": "2025-02-21T22:01:34.816761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    true_labels = [\n",
    "        [id2label[l] for l in label if l != -100]\n",
    "        for label in labels\n",
    "    ]\n",
    "    pred_labels = [\n",
    "        [id2label[p] for (p, l) in zip(pred, label) if l != -100]\n",
    "        for pred, label in zip(predictions, labels)\n",
    "    ]\n",
    "    results = seqeval.compute(predictions=pred_labels, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\":    results[\"overall_recall\"],\n",
    "        \"f1\":        results[\"overall_f1\"],\n",
    "        \"accuracy\":  results[\"overall_accuracy\"],\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T22:01:35.579758Z",
     "start_time": "2025-02-21T22:01:35.417810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Training arguments and Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./kb-bert-ner\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T08:34:12.327590Z",
     "start_time": "2025-02-21T22:02:42.696849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='238620' max='238620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [238620/238620 10:31:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.054914</td>\n",
       "      <td>0.965154</td>\n",
       "      <td>0.953774</td>\n",
       "      <td>0.959430</td>\n",
       "      <td>0.986021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.040552</td>\n",
       "      <td>0.974397</td>\n",
       "      <td>0.969932</td>\n",
       "      <td>0.972159</td>\n",
       "      <td>0.990229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.036804</td>\n",
       "      <td>0.980213</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.977684</td>\n",
       "      <td>0.992105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=238620, training_loss=0.050989647893191846, metrics={'train_runtime': 37889.0791, 'train_samples_per_second': 50.383, 'train_steps_per_second': 6.298, 'total_flos': 1.247067052857838e+17, 'train_loss': 0.050989647893191846, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:12:15.375549Z",
     "start_time": "2025-02-22T09:00:43.824252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19885' max='19885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19885/19885 11:12]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.036803822964429855, 'eval_precision': 0.9802129034275054, 'eval_recall': 0.9751673051303451, 'eval_f1': 0.9776835945315973, 'eval_accuracy': 0.9921051601198996, 'eval_runtime': 691.4805, 'eval_samples_per_second': 230.057, 'eval_steps_per_second': 28.757, 'epoch': 3.0}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:12:56.136481Z",
     "start_time": "2025-02-22T09:12:55.763357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save final model\n",
    "trainer.save_model(\"./kb-bert-ner-final\")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **5.2 Training Performance**\n",
    "Training was executed over **3 epochs**, and the model's **training loss** improved with each epoch:\n",
    "\n",
    "| Epoch | Training Loss | Validation Loss | Precision | Recall | F1 Score | Accuracy |\n",
    "|-------|--------------|----------------|------------|--------|----------|----------|\n",
    "| **1** | 0.0892       | 0.0549         | 0.9652     | 0.9538 | 0.9594   | 0.9860   |\n",
    "| **2** | 0.0424       | 0.0406         | 0.9744     | 0.9699 | 0.9722   | 0.9902   |\n",
    "| **3** | 0.0214       | 0.0368         | 0.9802     | 0.9752 | 0.9777   | 0.9921   |\n",
    "\n",
    "#### **Observations**\n",
    " **Training loss consistently decreased**, indicating that the model was effectively learning.  \n",
    " **Validation loss also decreased**, confirming improved generalization.  \n",
    " **F1 Score improved from 0.9594 to 0.9777**, showing stronger entity recognition.  \n",
    " **Final accuracy reached 99.21%**, demonstrating high performance.  \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##  Step 6: Entity Linking to Medical Ontologies\n",
    "After extracting named entities from Swedish medical texts, the next step is to **link these entities to standardized medical ontologies** such as **ICD-10, ICF, KSI, and others**. This ensures that recognized terms are mapped to official medical classifications, making them useful for clinical applications.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **6.1 Loading Medical Ontologies**\n",
    "We utilized classification files from **Socialstyrelsen** (Swedish National Board of Health and Welfare), including:\n",
    "- **ICD-10-SE** (International Classification of Diseases)\n",
    "- **ICF** (International Classification of Functioning, Disability, and Health)\n",
    "- **KSI** (Swedish Classification of Interventions)\n",
    "- **KVA-Kirurgiska** (Surgical procedures)\n",
    "- **KVA-Medicinska** (Medical procedures)\n",
    "- **U-Koder** (Urgent codes)\n",
    "\n",
    "Each ontology file was **parsed and cleaned**, keeping only the **code (Kod) and description (Titel)** for entity matching.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T21:52:47.581796Z",
     "start_time": "2025-02-23T21:52:47.402089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "ontology_files = {\n",
    "    \"icd-10-se.tsv\": \"ICD-10\",\n",
    "    \"icf.tsv\": \"ICF\",\n",
    "    \"ksi.tsv\": \"KSI\",\n",
    "    \"kva-kirurgiska-atgarder-kka.tsv\": \"KVA-Kirurgiska\",\n",
    "    \"kva-medicinska-atgarder-kma.tsv\": \"KVA-Medicinska\",\n",
    "    \"u-koder-kort-varsel.tsv\": \"U-Koder\"\n",
    "}\n",
    "\n",
    "data_path = \"data/classification\"\n",
    "\n",
    "ontology_data = {}\n",
    "\n",
    "for file, name in ontology_files.items():\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\", encoding=\"utf-8\", dtype=str)\n",
    "        ontology_data[name] = df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "for name, df in ontology_data.items():\n",
    "    if \"Kod\" in df.columns and \"Titel\" in df.columns:\n",
    "        ontology_data[name] = df[[\"Kod\", \"Titel\"]].dropna()"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T21:58:29.608802Z",
     "start_time": "2025-02-23T21:58:29.545220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_path = \"./kb-bert-ner-final\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "# Create NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"first\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **6.2 Named Entity Recognition (NER) on Sample Texts**"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T21:58:30.976790Z",
     "start_time": "2025-02-23T21:58:30.795169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample Swedish medical text\n",
    "sample_texts = [\n",
    "    \"Patienten har diabetes och högt blodtryck.\",\n",
    "    \"Han har en historia av hjärtinfarkt.\",\n",
    "    \"Astma har förvärrats och cancer har upptäckts.\"\n",
    "]\n",
    "\n",
    "# Run NER model\n",
    "extracted_entities = []\n",
    "for text in sample_texts:\n",
    "    ner_results = ner_pipeline(text)\n",
    "    for entity in ner_results:\n",
    "        extracted_entities.append(entity['word'])\n",
    "\n",
    "print(\"Extracted Entities:\", extracted_entities)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entities: ['hjärtinfarkt', 'Astma']\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model successfully extracted \"hjärtinfarkt\" and \"Astma\", which are relevant medical terms."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.3 Entity Matching to Ontologies"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T21:58:31.762691Z",
     "start_time": "2025-02-23T21:58:31.707237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def link_entities_to_ontology(entities, ontologies):\n",
    "    matched_results = []\n",
    "    \n",
    "    for entity in entities:\n",
    "        best_match = None\n",
    "        best_code = None\n",
    "        best_source = None\n",
    "        \n",
    "        for name, df in ontologies.items():\n",
    "            matches = df[df[\"Titel\"].str.contains(entity, case=False, na=False, regex=True)]\n",
    "            \n",
    "            if not matches.empty:\n",
    "                best_match = matches.iloc[0][\"Titel\"]\n",
    "                best_code = matches.iloc[0][\"Kod\"]\n",
    "                best_source = name\n",
    "                break  # Stop at the first found match\n",
    "        \n",
    "        matched_results.append({\n",
    "            \"Extracted Entity\": entity,\n",
    "            \"Matched Concept\": best_match if best_match else \"No match found\",\n",
    "            \"Ontology Code\": best_code if best_code else \"N/A\",\n",
    "            \"Ontology Source\": best_source if best_source else \"N/A\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(matched_results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracted Entity    Matched Concept Ontology Code Ontology Source\n",
      "0     hjärtinfarkt  Akut hjärtinfarkt           I21          ICD-10\n",
      "1            Astma              Astma           J45          ICD-10\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T21:59:35.901107Z",
     "start_time": "2025-02-23T21:59:35.842555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform entity linking\n",
    "linked_entities_df = link_entities_to_ontology(extracted_entities, ontology_data)\n",
    "\n",
    "# Display results\n",
    "linked_entities_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Extracted Entity    Matched Concept Ontology Code Ontology Source\n",
       "0     hjärtinfarkt  Akut hjärtinfarkt           I21          ICD-10\n",
       "1            Astma              Astma           J45          ICD-10"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extracted Entity</th>\n",
       "      <th>Matched Concept</th>\n",
       "      <th>Ontology Code</th>\n",
       "      <th>Ontology Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hjärtinfarkt</td>\n",
       "      <td>Akut hjärtinfarkt</td>\n",
       "      <td>I21</td>\n",
       "      <td>ICD-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Astma</td>\n",
       "      <td>Astma</td>\n",
       "      <td>J45</td>\n",
       "      <td>ICD-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We implemented ontology lookup using regular expression search to find the best match for each extracted entity.\n",
    "Both extracted entities were successfully matched to the ICD-10 medical ontology."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 7: Report the accuracy or other metrics and explainability (attention weights/SHAP/Other as relevant). "
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "After performing **Named Entity Recognition (NER) and linking extracted entities to medical ontologies**, we evaluate the accuracy of entity linking. This includes:\n",
    "- **Calculating precision, recall, F1-score, and accuracy**.\n",
    "- **Identifying mismatches and errors** in ontology linking.\n",
    "- **Exploring possible causes of errors and improvements**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2025-02-23T22:20:11.905919Z",
     "start_time": "2025-02-23T22:20:11.464823Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "expanded_test_entities = [\n",
    "    \"hjärtinfarkt\", \"Astma\", \"diabetes\", \"stroke\", \"cancer\", \"högt blodtryck\",\n",
    "    \"lunginflammation\", \"anemi\", \"migren\", \"benskörhet\", \"reumatoid artrit\",\n",
    "    \"förmaksflimmer\", \"njursvikt\", \"multipel skleros\", \"sköldkörtelrubbning\",\n",
    "    \"psoriasis\", \"parkinson\", \"demens\", \"leukemi\", \"akut bronkit\"\n",
    "]\n",
    "\n",
    "expanded_ground_truth = {\n",
    "    \"hjärtinfarkt\": \"I21\", \"Astma\": \"J45\", \"diabetes\": \"E10\", \"stroke\": \"I63\",\n",
    "    \"cancer\": \"C80\", \"högt blodtryck\": \"I10\", \"lunginflammation\": \"J18\", \"anemi\": \"D50\",\n",
    "    \"migren\": \"G43\", \"benskörhet\": \"M81\", \"reumatoid artrit\": \"M06\", \"förmaksflimmer\": \"I48\",\n",
    "    \"njursvikt\": \"N18\", \"multipel skleros\": \"G35\", \"sköldkörtelrubbning\": \"E03\", \"psoriasis\": \"L40\",\n",
    "    \"parkinson\": \"G20\", \"demens\": \"F03\", \"leukemi\": \"C91\", \"akut bronkit\": \"J20\"\n",
    "}\n",
    "\n",
    "expanded_linked_entities_df = link_entities_to_ontology(expanded_test_entities, ontology_data)\n",
    "y_true_expanded, y_pred_expanded = [], []\n",
    "for entity, true_code in expanded_ground_truth.items():\n",
    "    if entity in expanded_linked_entities_df[\"Extracted Entity\"].values:\n",
    "        pred_code = expanded_linked_entities_df[expanded_linked_entities_df[\"Extracted Entity\"] == entity][\"Ontology Code\"].values[0]\n",
    "        y_true_expanded.append(true_code)\n",
    "        y_pred_expanded.append(pred_code)\n",
    "\n",
    "expanded_accuracy = accuracy_score(y_true_expanded, y_pred_expanded)\n",
    "expanded_precision, expanded_recall, expanded_f1, _ = precision_recall_fscore_support(\n",
    "    y_true_expanded, y_pred_expanded, average=\"micro\"\n",
    ")\n",
    "\n",
    "expanded_accuracy_results = {\n",
    "    \"Accuracy\": expanded_accuracy,\n",
    "    \"Precision\": expanded_precision,\n",
    "    \"Recall\": expanded_recall,\n",
    "    \"F1-score\": expanded_f1\n",
    "}\n",
    "\n",
    "# Display results\n",
    "df_results = pd.DataFrame([expanded_accuracy_results])\n",
    "print(df_results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy  Precision  Recall  F1-score\n",
      "0       0.4        0.4     0.4       0.4\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **40% accuracy** indicates **room for improvement** in entity linking.\n",
    "- The model is **successful with direct matches** but **fails in ambiguous cases**."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.2 Error Analysis: Incorrect and Missing Mappings"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T22:21:27.619659Z",
     "start_time": "2025-02-23T22:21:27.613714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identify Errors\n",
    "mismatches = []\n",
    "\n",
    "for entity, true_code, pred_code in zip(expanded_ground_truth.keys(), y_true_expanded, y_pred_expanded):\n",
    "    if true_code != pred_code:\n",
    "        mismatches.append({\n",
    "            \"Entity\": entity,\n",
    "            \"True Code\": true_code,\n",
    "            \"Predicted Code\": pred_code\n",
    "        })\n",
    "\n",
    "# Display or save mismatches\n",
    "if mismatches:\n",
    "    mismatch_df = pd.DataFrame(mismatches)\n",
    "    print(\"Entity Linking Mismatches:\")\n",
    "    print(mismatch_df)\n",
    "    mismatch_df.to_csv(\"entity_linking_mismatches.csv\", index=False)\n",
    "else:\n",
    "    print(\"No mismatches found – all predictions are correct!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Linking Mismatches:\n",
      "                 Entity True Code Predicted Code\n",
      "0                stroke       I63         P91.0D\n",
      "1                cancer       C80          C22.1\n",
      "2      lunginflammation       J18        J09-J18\n",
      "3                 anemi       D50          D46.0\n",
      "4                migren       G43            N/A\n",
      "5            benskörhet       M81            N/A\n",
      "6      reumatoid artrit       M06            M05\n",
      "7             njursvikt       N18          I12.0\n",
      "8   sköldkörtelrubbning       E03            N/A\n",
      "9             parkinson       G20          F02.3\n",
      "10               demens       F03            F00\n",
      "11              leukemi       C91         C83.0A\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We identified **11 mismatches** between **predicted ontology codes** and **ground truth labels**."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7.3 Potential Causes of Errors\n",
    "1. **Ambiguous ICD-10 codes**\n",
    "   - Some conditions have **multiple valid codes** (e.g., `\"stroke\"` → `I63` vs. `P91.0D`).\n",
    "   - The model may **select a related but incorrect code**.\n",
    "\n",
    "2. **Synonym variations**\n",
    "   - `\"parkinson\"` was mapped to `\"F02.3\"` (dementia due to Parkinson’s) instead of `\"G20\"` (Parkinson’s disease).\n",
    "   - `\"demens\"` was mapped to `\"F00\"` (Alzheimer’s-related dementia) instead of `\"F03\"` (unspecified dementia).\n",
    "\n",
    "3. **Issues with Partial Matches**\n",
    "   - `\"lunginflammation\"` (pneumonia) was mapped to `\"J09-J18\"` (entire range of influenza and pneumonia).\n",
    "   - `\"anemi\"` was incorrectly mapped to `\"D46.0\"` (refractory anemia) instead of `\"D50\"` (iron deficiency anemia).\n",
    "\n",
    "4. **Missing Terms in Ontology**\n",
    "   - `\"migren\"`, `\"benskörhet\"`, and `\"sköldkörtelrubbning\"` had **no match found**.\n",
    "   - This suggests that **some medical terms were missing from the ontology dataset**."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7.4 Explainability: Improving Entity Linking\n",
    "To improve **ontology matching**, future work should include:\n",
    "- **Fuzzy matching** (handling minor spelling variations).\n",
    "- **Confidence thresholds** (assigning certainty scores to matches).\n",
    "- **ML-based classification** (training a model for better ICD-10 prediction)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    " **Named Entity Recognition (NER) was successfully performed using Kb-BERT.**  \n",
    " **Entities were linked to medical ontologies, achieving partial success.**  \n",
    " **The accuracy of entity linking (40%) suggests improvements are needed.**  \n",
    "️ **Ambiguous and missing mappings require better handling strategies.**  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
